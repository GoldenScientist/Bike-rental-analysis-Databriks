{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession \nsc = SparkSession.builder.master(\"local[*]\").getOrCreate()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["data = sc.read.csv(\"/FileStore/tables/Bike_Rental_UCI_dataset-bb6c6.csv\",inferSchema=True,header=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["data.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\nseason| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\n     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|\n     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|\n     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|\n     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|\n     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|\n     1|  0|   1|  5|      0|         0|         2|0.24|0.75|   0.0896|      Sat|   0|     1|\n     1|  0|   1|  6|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|     2|\n     1|  0|   1|  7|      0|         0|         1| 0.2|0.86|      0.0|      Sat|   0|     3|\n     1|  0|   1|  8|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     8|\n     1|  0|   1|  9|      0|         0|         1|0.32|0.76|      0.0|      Sat|   0|    14|\n     1|  0|   1| 10|      0|         0|         1|0.38|0.76|   0.2537|      Sat|   0|    36|\n     1|  0|   1| 11|      0|         0|         1|0.36|0.81|   0.2836|      Sat|   0|    56|\n     1|  0|   1| 12|      0|         0|         1|0.42|0.77|   0.2836|      Sat|   0|    84|\n     1|  0|   1| 13|      0|         0|         2|0.46|0.72|   0.2985|      Sat|   0|    94|\n     1|  0|   1| 14|      0|         0|         2|0.46|0.72|   0.2836|      Sat|   0|   106|\n     1|  0|   1| 15|      0|         0|         2|0.44|0.77|   0.2985|      Sat|   0|   110|\n     1|  0|   1| 16|      0|         0|         2|0.42|0.82|   0.2985|      Sat|   0|    93|\n     1|  0|   1| 17|      0|         0|         2|0.44|0.82|   0.2836|      Sat|   0|    67|\n     1|  0|   1| 18|      0|         0|         3|0.42|0.88|   0.2537|      Sat|   0|    35|\n     1|  0|   1| 19|      0|         0|         3|0.42|0.88|   0.2537|      Sat|   0|    37|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["from pyspark.ml.classification import (LogisticRegression,DecisionTreeClassifier,RandomForestClassifier)\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.tuning import ParamGridBuilder,CrossValidator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import StringIndexer"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["indexer = StringIndexer(inputCol=\"dayOfWeek\",outputCol=\"day_cat\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["indexed_data = indexer.fit(data).transform(data)\nindexed_data.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\nseason| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|day_cat|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\n     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|    0.0|\n     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|    0.0|\n     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|    0.0|\n     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|    0.0|\n     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|    0.0|\n     1|  0|   1|  5|      0|         0|         2|0.24|0.75|   0.0896|      Sat|   0|     1|    0.0|\n     1|  0|   1|  6|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|     2|    0.0|\n     1|  0|   1|  7|      0|         0|         1| 0.2|0.86|      0.0|      Sat|   0|     3|    0.0|\n     1|  0|   1|  8|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     8|    0.0|\n     1|  0|   1|  9|      0|         0|         1|0.32|0.76|      0.0|      Sat|   0|    14|    0.0|\n     1|  0|   1| 10|      0|         0|         1|0.38|0.76|   0.2537|      Sat|   0|    36|    0.0|\n     1|  0|   1| 11|      0|         0|         1|0.36|0.81|   0.2836|      Sat|   0|    56|    0.0|\n     1|  0|   1| 12|      0|         0|         1|0.42|0.77|   0.2836|      Sat|   0|    84|    0.0|\n     1|  0|   1| 13|      0|         0|         2|0.46|0.72|   0.2985|      Sat|   0|    94|    0.0|\n     1|  0|   1| 14|      0|         0|         2|0.46|0.72|   0.2836|      Sat|   0|   106|    0.0|\n     1|  0|   1| 15|      0|         0|         2|0.44|0.77|   0.2985|      Sat|   0|   110|    0.0|\n     1|  0|   1| 16|      0|         0|         2|0.42|0.82|   0.2985|      Sat|   0|    93|    0.0|\n     1|  0|   1| 17|      0|         0|         2|0.44|0.82|   0.2836|      Sat|   0|    67|    0.0|\n     1|  0|   1| 18|      0|         0|         3|0.42|0.88|   0.2537|      Sat|   0|    35|    0.0|\n     1|  0|   1| 19|      0|         0|         3|0.42|0.88|   0.2537|      Sat|   0|    37|    0.0|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["indexed_data.select('day_cat').distinct().orderBy('day_cat').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+\nday_cat|\n+-------+\n    0.0|\n    1.0|\n    2.0|\n    3.0|\n    4.0|\n    5.0|\n    6.0|\n+-------+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nvec = VectorAssembler(inputCols=['season','yr','mnth','hr','holiday','workingday','weathersit','days','day_cat'],outputCol='features')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["data1 = vec.transform(indexed_data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["data1.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+--------------------+\nseason| yr|mnth| hr|holiday|workingday|weathersit|temp| hum|windspeed|dayOfWeek|days|demand|day_cat|            features|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+--------------------+\n     1|  0|   1|  0|      0|         0|         1|0.24|0.81|      0.0|      Sat|   0|    16|    0.0|(9,[0,2,6],[1.0,1...|\n     1|  0|   1|  1|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    40|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1|  2|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|    32|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1|  3|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|    13|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1|  4|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     1|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1|  5|      0|         0|         2|0.24|0.75|   0.0896|      Sat|   0|     1|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1|  6|      0|         0|         1|0.22| 0.8|      0.0|      Sat|   0|     2|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1|  7|      0|         0|         1| 0.2|0.86|      0.0|      Sat|   0|     3|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1|  8|      0|         0|         1|0.24|0.75|      0.0|      Sat|   0|     8|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1|  9|      0|         0|         1|0.32|0.76|      0.0|      Sat|   0|    14|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 10|      0|         0|         1|0.38|0.76|   0.2537|      Sat|   0|    36|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 11|      0|         0|         1|0.36|0.81|   0.2836|      Sat|   0|    56|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 12|      0|         0|         1|0.42|0.77|   0.2836|      Sat|   0|    84|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 13|      0|         0|         2|0.46|0.72|   0.2985|      Sat|   0|    94|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 14|      0|         0|         2|0.46|0.72|   0.2836|      Sat|   0|   106|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 15|      0|         0|         2|0.44|0.77|   0.2985|      Sat|   0|   110|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 16|      0|         0|         2|0.42|0.82|   0.2985|      Sat|   0|    93|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 17|      0|         0|         2|0.44|0.82|   0.2836|      Sat|   0|    67|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 18|      0|         0|         3|0.42|0.88|   0.2537|      Sat|   0|    35|    0.0|(9,[0,2,3,6],[1.0...|\n     1|  0|   1| 19|      0|         0|         3|0.42|0.88|   0.2537|      Sat|   0|    37|    0.0|(9,[0,2,3,6],[1.0...|\n+------+---+----+---+-------+----------+----------+----+----+---------+---------+----+------+-------+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["modelData = data1.select('features','demand')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["modelData.describe().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------------------+\nsummary|            demand|\n+-------+------------------+\n  count|             17379|\n   mean|189.46308763450142|\n stddev| 181.3875990918646|\n    min|                 1|\n    max|               977|\n+-------+------------------+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["modelData.show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------+------+\nfeatures                        |demand|\n+--------------------------------+------+\n(9,[0,2,6],[1.0,1.0,1.0])       |16    |\n(9,[0,2,3,6],[1.0,1.0,1.0,1.0]) |40    |\n(9,[0,2,3,6],[1.0,1.0,2.0,1.0]) |32    |\n(9,[0,2,3,6],[1.0,1.0,3.0,1.0]) |13    |\n(9,[0,2,3,6],[1.0,1.0,4.0,1.0]) |1     |\n(9,[0,2,3,6],[1.0,1.0,5.0,2.0]) |1     |\n(9,[0,2,3,6],[1.0,1.0,6.0,1.0]) |2     |\n(9,[0,2,3,6],[1.0,1.0,7.0,1.0]) |3     |\n(9,[0,2,3,6],[1.0,1.0,8.0,1.0]) |8     |\n(9,[0,2,3,6],[1.0,1.0,9.0,1.0]) |14    |\n(9,[0,2,3,6],[1.0,1.0,10.0,1.0])|36    |\n(9,[0,2,3,6],[1.0,1.0,11.0,1.0])|56    |\n(9,[0,2,3,6],[1.0,1.0,12.0,1.0])|84    |\n(9,[0,2,3,6],[1.0,1.0,13.0,2.0])|94    |\n(9,[0,2,3,6],[1.0,1.0,14.0,2.0])|106   |\n(9,[0,2,3,6],[1.0,1.0,15.0,2.0])|110   |\n(9,[0,2,3,6],[1.0,1.0,16.0,2.0])|93    |\n(9,[0,2,3,6],[1.0,1.0,17.0,2.0])|67    |\n(9,[0,2,3,6],[1.0,1.0,18.0,3.0])|35    |\n(9,[0,2,3,6],[1.0,1.0,19.0,3.0])|37    |\n+--------------------------------+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["trainData,testData = modelData.randomSplit([0.7,0.3])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["trainData = trainData.withColumnRenamed(('demand'),('label'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["testData = testData.withColumnRenamed(('demand'), ('label'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["trainData.show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------+-----+\nfeatures                        |label|\n+--------------------------------+-----+\n(9,[0,2,3,6],[1.0,1.0,1.0,1.0]) |40   |\n(9,[0,2,3,6],[1.0,1.0,2.0,1.0]) |32   |\n(9,[0,2,3,6],[1.0,1.0,5.0,2.0]) |1    |\n(9,[0,2,3,6],[1.0,1.0,6.0,1.0]) |2    |\n(9,[0,2,3,6],[1.0,1.0,10.0,1.0])|36   |\n(9,[0,2,3,6],[1.0,1.0,11.0,1.0])|56   |\n(9,[0,2,3,6],[1.0,1.0,12.0,1.0])|84   |\n(9,[0,2,3,6],[1.0,1.0,14.0,2.0])|106  |\n(9,[0,2,3,6],[1.0,1.0,15.0,2.0])|110  |\n(9,[0,2,3,6],[1.0,1.0,16.0,2.0])|93   |\n(9,[0,2,3,6],[1.0,1.0,17.0,2.0])|67   |\n(9,[0,2,3,6],[1.0,1.0,19.0,3.0])|37   |\n(9,[0,2,3,6],[1.0,1.0,20.0,2.0])|36   |\n(9,[0,2,3,6],[1.0,1.0,21.0,2.0])|34   |\n(9,[0,2,3,6],[1.0,1.0,22.0,2.0])|28   |\n(9,[0,2,6],[1.0,1.0,1.0])       |16   |\n(9,[0,2,6,7],[1.0,1.0,1.0,13.0])|28   |\n(9,[0,2,6,7],[1.0,1.0,1.0,19.0])|13   |\n(9,[0,2,6,7],[1.0,1.0,1.0,25.0])|28   |\n(9,[0,2,6,7],[1.0,1.0,2.0,6.0]) |25   |\n+--------------------------------+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["testData.show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------+-----+\nfeatures                          |label|\n+----------------------------------+-----+\n(9,[0,2,3,6],[1.0,1.0,3.0,1.0])   |13   |\n(9,[0,2,3,6],[1.0,1.0,4.0,1.0])   |1    |\n(9,[0,2,3,6],[1.0,1.0,7.0,1.0])   |3    |\n(9,[0,2,3,6],[1.0,1.0,8.0,1.0])   |8    |\n(9,[0,2,3,6],[1.0,1.0,9.0,1.0])   |14   |\n(9,[0,2,3,6],[1.0,1.0,13.0,2.0])  |94   |\n(9,[0,2,3,6],[1.0,1.0,18.0,3.0])  |35   |\n(9,[0,2,3,6],[1.0,1.0,23.0,2.0])  |39   |\n(9,[0,2,6,7],[1.0,2.0,1.0,46.0])  |29   |\n(9,[0,2,6,7],[1.0,3.0,2.0,73.0])  |76   |\n(9,[0,2,6,7],[1.0,12.0,2.0,359.0])|44   |\n(9,[0,2,6,7],[2.0,4.0,2.0,101.0]) |43   |\n(9,[0,2,6,7],[2.0,5.0,1.0,136.0]) |98   |\n(9,[0,2,6,7],[2.0,6.0,1.0,157.0]) |117  |\n(9,[0,2,6,7],[3.0,6.0,1.0,171.0]) |116  |\n(9,[0,2,6,7],[3.0,7.0,1.0,178.0]) |115  |\n(9,[0,2,6,7],[3.0,7.0,1.0,199.0]) |101  |\n(9,[0,2,6,7],[3.0,7.0,1.0,206.0]) |133  |\n(9,[0,2,6,7],[3.0,8.0,1.0,220.0]) |84   |\n(9,[0,2,6,7],[4.0,9.0,1.0,261.0]) |93   |\n+----------------------------------+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\nlr = LinearRegression(featuresCol ='features', labelCol='label', maxIter=1000, regParam=0.8, elasticNetParam=1)\nlr_model = lr.fit(trainData)\nprint(\"Coefficients: \" + str(lr_model.coefficients))\nprint(\"Intercept: \" + str(lr_model.intercept))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Coefficients: [35.1740391753,91.035953909,-2.86162495611,10.1176849702,-19.9490960265,9.29596739756,-34.7054324757,0.0,0.0]\nIntercept: 0.30424906816367053\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["trainingSummary = lr_model.summary\nprint(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\nprint(\"r2: %f\" % trainingSummary.r2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">RMSE: 153.822058\nr2: 0.271404\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.tuning import ParamGridBuilder,CrossValidator"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["from pyspark.ml.classification import MultilayerPerceptronClassifier"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["layers =[4,5,4,3]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["classifier = MultilayerPerceptronClassifier(maxIter=1000,layers=layers)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["gridBuilder=ParamGridBuilder().addGrid(classifier.layers,[[4,2,3,3],[4,2,2,3],[4,10,3]]).addGrid(classifier.stepSize,[0.03,0.01]).build()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"code","source":["pipeLine=Pipeline()\npipeLine.setStages((classifier))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">133</span><span class=\"ansired\">]: </span>Pipeline_7ef0bbbe2de6</div>"]}}],"execution_count":26},{"cell_type":"code","source":["evaluator=MulticlassClassificationEvaluator(metricName='f1')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["cv = CrossValidator(estimator=pipeLine,estimatorParamMaps=gridBuilder,evaluator=evaluator)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["model = pipeLine.fit(trainData)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-4151223953939292&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>model <span class=\"ansiyellow\">=</span> pipeLine<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>trainData<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n<span class=\"ansigreen\">    130</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    131</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 132</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    133</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    134</span>             raise ValueError(&quot;Params must be either a param map or a list/tuple of param maps, &quot;\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/pipeline.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">     92</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     93</span>         stages <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>getStages<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 94</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">for</span> stage <span class=\"ansigreen\">in</span> stages<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     95</span>             <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> <span class=\"ansiyellow\">(</span>isinstance<span class=\"ansiyellow\">(</span>stage<span class=\"ansiyellow\">,</span> Estimator<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">or</span> isinstance<span class=\"ansiyellow\">(</span>stage<span class=\"ansiyellow\">,</span> Transformer<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     96</span>                 raise TypeError(\n\n<span class=\"ansired\">TypeError</span>: &apos;MultilayerPerceptronClassifier&apos; object is not iterable</div>"]}}],"execution_count":29},{"cell_type":"code","source":["preds = classifier.fit(trainData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-4151223953939294&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>preds <span class=\"ansiyellow\">=</span> classifier<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>trainData<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansicyan\">fit</span><span class=\"ansiblue\">(self, dataset, params)</span>\n<span class=\"ansigreen\">    130</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    131</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 132</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    133</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    134</span>             raise ValueError(&quot;Params must be either a param map or a list/tuple of param maps, &quot;\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_fit</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">    293</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    294</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 295</span><span class=\"ansiyellow\">         </span>java_model <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_fit_java<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    296</span>         model <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_create_model<span class=\"ansiyellow\">(</span>java_model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    297</span>         <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_copyValues<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_fit_java</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">    290</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    291</span>         self<span class=\"ansiyellow\">.</span>_transfer_params_to_java<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 292</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_java_obj<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    293</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    294</span>     <span class=\"ansigreen\">def</span> _fit<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    327</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 328</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    329</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    330</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o2890.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 117.0 failed 1 times, most recent failure: Lost task 0.0 in stage 117.0 (TID 1112, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$org$apache$spark$ml$feature$OneHotEncoderModel$$encoder$1: (double, int) =&gt; struct&lt;type:tinyint,size:int,indices:array&lt;int&gt;,values:array&lt;double&gt;&gt;)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:640)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1170)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1161)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1096)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1161)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:883)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:351)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:302)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:139)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:112)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1526)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:503)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Unseen value: 40.0. To handle unseen values, set Param handleInvalid to keep.\n\tat org.apache.spark.ml.feature.OneHotEncoderModel$$anonfun$org$apache$spark$ml$feature$OneHotEncoderModel$$encoder$1.apply(OneHotEncoderEstimator.scala:258)\n\tat org.apache.spark.ml.feature.OneHotEncoderModel$$anonfun$org$apache$spark$ml$feature$OneHotEncoderModel$$encoder$1.apply(OneHotEncoderEstimator.scala:244)\n\t... 28 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2355)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2343)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2342)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2342)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1096)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1096)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1096)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2574)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2510)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:893)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2243)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2265)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2309)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1184)\n\tat org.apache.spark.mllib.optimization.LBFGS$.runLBFGS(LBFGS.scala:195)\n\tat org.apache.spark.mllib.optimization.LBFGS.optimize(LBFGS.scala:142)\n\tat org.apache.spark.ml.ann.FeedForwardTrainer.train(Layer.scala:854)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier$$anonfun$train$1.apply(MultilayerPerceptronClassifier.scala:249)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier$$anonfun$train$1.apply(MultilayerPerceptronClassifier.scala:205)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$14.apply(Instrumentation.scala:277)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:277)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:205)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:114)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:120)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$org$apache$spark$ml$feature$OneHotEncoderModel$$encoder$1: (double, int) =&gt; struct&lt;type:tinyint,size:int,indices:array&lt;int&gt;,values:array&lt;double&gt;&gt;)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:640)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1170)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1161)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1096)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1161)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:883)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:351)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:302)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:139)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:112)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1526)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:503)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Unseen value: 40.0. To handle unseen values, set Param handleInvalid to keep.\n\tat org.apache.spark.ml.feature.OneHotEncoderModel$$anonfun$org$apache$spark$ml$feature$OneHotEncoderModel$$encoder$1.apply(OneHotEncoderEstimator.scala:258)\n\tat org.apache.spark.ml.feature.OneHotEncoderModel$$anonfun$org$apache$spark$ml$feature$OneHotEncoderModel$$encoder$1.apply(OneHotEncoderEstimator.scala:244)\n\t... 28 more\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["lr = LogisticRegression()\ndt = DecisionTreeClassifier()\nrf = RandomForestClassifier(maxBins=10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31}],"metadata":{"name":"accessment","notebookId":4151223953939258},"nbformat":4,"nbformat_minor":0}
